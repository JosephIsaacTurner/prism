import numpy as np
from scipy.stats import genpareto
from tqdm import tqdm
from .stats import fdr_bh_correction


def permutation_analysis(data, design, contrast, stat_function, n_permutations, random_seed, two_tailed=True, exchangeability_matrix=None, within=True, whole=False, accel_tail=True):
    """
    Performs permutation testing on the provided data using a specified statistical function.
    
    The function calculates the observed (true) test statistics, then generates a null distribution
    by permuting the design matrix (optionally respecting an exchangeability structure). It computes:
      - Empirical (uncorrected) p-values,
      - FDR-corrected p-values via the Benjamini-Hochberg procedure,
      - FWE-corrected p-values using a max-statistic approach (with an option for accelerated tail estimation via a GPD fit).
    
    Parameters
    ----------
    data : np.ndarray, shape (n_samples, n_elements_per_sample)
        The data matrix, where each row represents a sample and each column an element/feature.
    design : np.ndarray, shape (n_samples, n_features)
        The design matrix for the GLM, where each row corresponds to a sample and each column to a regressor.
    contrast : np.ndarray, shape (n_features,) or (n_contrasts, n_features)
        The contrast vector or matrix specifying the hypothesis to be tested.
    stat_function : function
        A function that calculates the test statistic. It must accept the arguments (data, design, contrast)
        and return an array of test statistics. The shape of its output defines the shape of the result.
    n_permutations : int
        The number of permutations to perform.
    random_seed : int
        Seed for the random number generator to ensure reproducibility.
    two_tailed : bool, default True
        If True, p-values are computed in a two-tailed manner using absolute values of statistics.
    exchangeability_matrix : np.ndarray, optional
        Defines the exchangeability blocks for permutation testing. Expected shapes:
          - If provided as a vector: (n_samples,) or (n_samples, 1).
          - If provided as a matrix: (n_samples, n_permutation_groups).
    within : bool, default True
        For a 1D exchangeability matrix, indicates whether to permute within blocks.
    whole : bool, default False
        For a 1D exchangeability matrix, indicates whether to permute whole blocks.
    accel_tail : bool, default True
        If True, applies the accelerated tail method (GPD approximation) to compute p-values for cases with 
        low empirical exceedance counts.
    
    Returns
    -------
    unc_p : np.ndarray
        Uncorrected p-values computed empirically from the permutation distribution. 
        Shape matches that of the test statistic returned by `stat_function`.
    fdr_p : np.ndarray
        P-values corrected for multiple comparisons using the Benjamini-Hochberg procedure.
        Shape matches that of the test statistic returned by `stat_function`.
    fwe_p : np.ndarray or float
        Family-wise error rate (FWE) corrected p-values computed using the max-statistic approach.
        If `two_tailed` is True, the p-values are based on absolute values of statistics.
    
    Notes
    -----
    - The first dimension of both `data` and `design` is assumed to correspond to the samples (subjects).
    - The true test statistic is computed once using `stat_function`, and the null distribution is built by
      applying the same function on permuted versions of the design matrix generated by `yield_permuted_stats`.
    """
    # Step One: Calculate the true statistics
    true_stats = stat_function(data, design, contrast)
    # Step Two: Run the permutations
    exceedances = np.zeros(true_stats.shape)
    permutation_generator = yield_permuted_stats(
        data, design, contrast,
        stat_function=stat_function,
        n_permutations=n_permutations,
        random_seed=random_seed,
        exchangeability_matrix=exchangeability_matrix,
        within=within,
        whole=whole
    )
    for i in tqdm(range(n_permutations), desc="Permuting..."):
        permuted_stats = next(permutation_generator)
        if two_tailed:
            exceedances += np.abs(permuted_stats) >= np.abs(true_stats)
            max_stat_dist = np.hstack([np.max(np.abs(permuted_stats)), max_stat_dist]) if i > 0 else np.max(np.abs(permuted_stats))
        else:
            exceedances += permuted_stats >= true_stats
            max_stat_dist = np.hstack([np.max(permuted_stats), max_stat_dist]) if i > 0 else np.max(permuted_stats)
    # Step Three: Calculate uncorrected p-values
    unc_p = exceedances / n_permutations
    # Step Four: Correct using FDR (Benjamini-Hochberg)
    fdr_p = fdr_bh_correction(unc_p)
    # Step Five: Correct using FWE (max-stat i.e. Westfall-Young)
    if accel_tail:
        # Use a generalized Pareto distribution to estimate p-values for the tail.
        fwe_p = compute_p_values_accel_tail(true_stats, max_stat_dist, two_tailed=two_tailed)
    else:
        if two_tailed:
            fwe_p = np.sum(max_stat_dist >= np.abs(true_stats)) / n_permutations
        else:
            fwe_p = np.sum(max_stat_dist >= true_stats) / n_permutations
    return unc_p, fdr_p, fwe_p


def yield_permuted_stats(data, design, contrast, stat_function, n_permutations, random_seed, exchangeability_matrix=None, within=True, whole=False):
    """Generator function for permutation testing.
    data: Shape (n_samples, n_elements_per_sample)
    design: Shape (n_samples, n_features)
    contrast: Shape (n_features,) or (n_contrasts, n_features)
    stat_function: Function that calculates the test statistic. Must take data, design, contrast as arguments.
    n_permutations: Number of permutations to perform.
    random_seed: Random seed for reproducibility.
    exchangeability_matrix (Optional): Exchangeability matrix for permutation testing. Shape (n_samples,) or (n_samples, n_permutation_groups).
    """
    calculate = stat_function
    permuted_design_generator = yield_permuted_design(design, n_permutations, random_seed, exchangeability_matrix, within, whole)
    for i in range(n_permutations):
        permuted_value = calculate(data, next(permuted_design_generator), contrast)
        yield permuted_value


def yield_permuted_design(design, n_permutations, random_seed, exchangeability_matrix=None, within=True, whole=False):
    """Generator for permuting the design matrix per PALM documentation.
    
    Docs: https://web.mit.edu/fsl_v5.0.10/fsl/doc/wiki/PALM(2f)ExchangeabilityBlocks.html

    - design: Shape (n_samples, n_features)
    - n_permutations: Number of permutations to generate.
    - random_seed: Random seed for reproducibility (OK if None).
    - exchangeability_matrix (Optional): Either a vector of length n_samples or a matrix as described.
    - within (Optional): Whether to permute within the exchangeability blocks (default True).
      (Ignored if exchangeability_matrix is 2D.)
    - whole (Optional): Whether to permute whole blocks (default False).
      (Ignored if exchangeability_matrix is 2D.)
    
    Note: within and whole are mutually exclusive for 1D exchangeability.
    """
    rnd = np.random.RandomState(random_seed)
    n_samples = design.shape[0]
    
    # Case 1: Freely exchangeable data
    if exchangeability_matrix is None:
        for _ in range(n_permutations):
            yield design[rnd.permutation(n_samples)]
        return
    
    # Ensure exchangeability_matrix is in the correct shape.
    exchangeability_matrix = np.atleast_2d(exchangeability_matrix)
    # If a vector was passed, np.atleast_2d makes it shape (1, n_samples);
    # transpose it so that each row corresponds to an observation.
    if exchangeability_matrix.shape[0] == 1 and exchangeability_matrix.shape[1] == n_samples:
        exchangeability_matrix = exchangeability_matrix.T
    if exchangeability_matrix.shape[0] != n_samples:
        raise ValueError("Exchangeability matrix rows must equal design rows.")
    
    # Case 2: Single-column exchangeability
    if exchangeability_matrix.shape[1] == 1:
        blocks = exchangeability_matrix.ravel()
        uniq, first_idx = np.unique(blocks, return_index=True)
        order_unique = uniq[np.argsort(first_idx)]
        block_to_idx = {b: np.flatnonzero(blocks == b) for b in order_unique}
        for _ in range(n_permutations):
            if whole:
                permuted_blocks = rnd.permutation(order_unique)
                perm_order = np.concatenate([block_to_idx[b] for b in permuted_blocks])
            else:
                perm_order = np.concatenate([rnd.permutation(block_to_idx[b]) for b in order_unique])
            yield design[perm_order]
        return

    # Case 3: Multi-column exchangeability; flags (within, whole) are ignored.
    def recursive_permute(indices, blocks, rnd):
        if blocks.shape[1] == 0:
            return indices
        new_order = []
        uniq = np.unique(blocks[:, 0])
        for label in uniq:
            idx = np.flatnonzero(blocks[:, 0] == label)
            sub_idx = [indices[i] for i in idx]
            if blocks.shape[1] > 1:
                sub_blocks = blocks[idx, 1:]
                # For a positive label, treat as whole-block (keep order); for negative, shuffle within.
                new_order.extend(recursive_permute(sub_idx, sub_blocks, rnd) if label > 0 
                                else recursive_permute(rnd.permutation(sub_idx), sub_blocks, rnd))
            else:
                new_order.extend(rnd.permutation(sub_idx) if label < 0 and len(sub_idx) > 1 else sub_idx)
        return new_order

    all_idx = list(range(n_samples))
    blocks = exchangeability_matrix.astype(float)
    for _ in range(n_permutations):
        perm_order = recursive_permute(all_idx, blocks, rnd)
        yield design[np.array(perm_order)]

def compute_p_values_accel_tail(true_values, null_dist, threshold=None, two_tailed=False):
    """
    Computes p-values for a vector of observed test statistics based on an empirical null distribution.
    For each observed test statistic, if the number of permutation values greater than or equal to it (or its absolute value)
    is >= 10, the p-value is computed using the empirical method. Otherwise, a Generalized Pareto Distribution (GPD)
    is fitted to the tail (exceedances) of the null distribution to extrapolate the p-value.
    
    Parameters
    ----------
    true_values : float or array-like of shape (n_elements,)
        The observed test statistic(s). Can be a single value or a vector.
    null_dist : array-like
        The empirical null distribution (from permutations).
    threshold : float, optional
        The threshold for defining "exceedances" in the tail.
        If None, defaults to the 90th percentile of the (possibly absolute) null_dist.
        IMPORTANT: The threshold should be less than the observed test statistic (or its absolute value).
        If it isn’t, it will be lowered based on the data.
    two_tailed : bool, default False
        If True, a two-tailed test is performed by using the absolute values of the test statistics and the null distribution.
    
    Returns
    -------
    p_values : np.ndarray
        Array of p-values corresponding to each observed test statistic.
    
    Notes
    -----
    For the GPD approximation (applied when M < 10 for an observed test statistic):
      - Let t be the threshold.
      - Define exceedances as the values in null_dist (or abs(null_dist) if two_tailed) that are greater than t.
      - Fit a GPD (with location fixed to 0) to the excesses: z = y - t.
      - The p-value is given by:
             p_gpd = (N_exc / N) * (1 - F(|x₀| - t)),
        where F is the GPD CDF, N_exc is the number of exceedances, N is the total number of permutations,
        and x₀ is the observed test statistic.
    """
    # Convert inputs to numpy arrays.
    true_values = np.atleast_1d(true_values)
    null_arr = np.asarray(null_dist)
    N = len(null_arr)
    
    # If two_tailed, use absolute values.
    if two_tailed:
        observed = np.abs(true_values)
        null_arr = np.abs(null_arr)
    else:
        observed = true_values

    p_values = np.empty_like(observed, dtype=float)
    
    # Vectorized calculation of exceedance counts for all test statistics.
    # Using broadcasting to compare each observed value with the null distribution.
    comparisons = null_arr >= observed[:, None]
    M = comparisons.sum(axis=1)
    
    # Empirical p-values (vectorized)
    p_emp = (M + 1) / (N + 1)
    
    # Boolean mask for indices where the empirical method is valid. We use the empirical distribution for the bottom 95% of the true values if greater than 20000.
    empirical_mask = np.logical_or(M >= 10, true_values < np.percentile(observed, 95)) if observed.shape[0] > 20000 else M >= 10
    p_values[empirical_mask] = p_emp[empirical_mask]
    
    # For cases requiring the GPD approximation.
    gpd_indices = np.where(~empirical_mask)[0]
    if len(gpd_indices) == 0:
        return p_values
    for i in tqdm(gpd_indices, desc="Computing GPD p-values") if len(gpd_indices) > 1 else gpd_indices:
        t_val = observed[i]
        M_i = M[i]
        
        # Determine threshold to use.
        if threshold is None:
            t_threshold = np.percentile(null_arr, 90)
        else:
            t_threshold = threshold
        
        # Ensure that t_threshold is less than t_val.
        if t_threshold >= t_val:
            below = null_arr[null_arr < t_val]
            if below.size > 0:
                t_threshold = np.min(below)
            # Else: if no null value is below t_val, leave t_threshold as is.
        
        # Identify exceedances above the threshold.
        exceedances = null_arr[null_arr > t_threshold]
        N_exc = len(exceedances)
        
        # If no exceedances exist, fall back to the empirical method.
        if N_exc == 0:
            p_values[i] = (M_i + 1) / (N + 1)
        else:
            # Compute excesses above the threshold.
            excesses = exceedances - t_threshold
            
            # Fit the GPD to the excesses with location fixed at 0.
            shape, _, scale = genpareto.fit(excesses, floc=0)
            
            # Calculate the excess for the observed statistic.
            x_excess = t_val - t_threshold
            if x_excess < 0:
                cdf_val = 0.0
            else:
                cdf_val = genpareto.cdf(x_excess, shape, loc=0, scale=scale)
            
            # Compute the GPD-based p-value.
            p_gpd = (N_exc / N) * (1 - cdf_val)
            p_values[i] = p_gpd

    return p_values